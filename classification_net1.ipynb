{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 폴더로 경로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ./disk1/colonoscopy_datasetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom DataLoader 구현 - mask 이미지는 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 한번에 불러오는 코드\n",
    "class CustomDataset(Dataset):\n",
    "    def readData(self):\n",
    "        all_files_path = []\n",
    "        all_labels = []\n",
    "        \n",
    "        class_names = os.walk(self.dataset_path).__next__()[1]\n",
    "\n",
    "        for idx, class_name in enumerate(class_names):\n",
    "            img_dir = os.path.join(self.dataset_path, class_name)\n",
    "            img_file_names = os.walk(img_dir).__next__()[2]\n",
    "\n",
    "            for img_name in img_file_names:\n",
    "                # masked 이미지는 제외\n",
    "                if img_name[4:8] == 'MASK':\n",
    "                    continue\n",
    "\n",
    "                img_file_path = os.path.join(img_dir, img_name)\n",
    "                image = Image.open(img_file_path)\n",
    "\n",
    "                if image is not None:\n",
    "                    all_files_path.append(img_file_path)\n",
    "                    all_labels.append(idx)\n",
    "\n",
    "        return all_files_path, all_labels, len(all_labels), len(class_names)\n",
    "            \n",
    "    def __init__(self, dataset_path, transforms=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.files_path, self.labels, self.num_files, self.num_classes = self.readData()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.files_path[index])\n",
    "        label = self.labels[index]\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return {'image': image, 'label': label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom DataLoader 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_class_names = os.walk(\"./cropped\").__next__()[1]\n",
    "print(sample_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transforms = transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor()])                                  \n",
    "sample_dataset = CustomDataset(\"./cropped\", transforms=sample_transforms)\n",
    "sample_loader = DataLoader(sample_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 구성 확인 - masked image는 제외한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "num_nor0 = 0\n",
    "num_adc1 = 0\n",
    "num_hgd2 = 0\n",
    "num_lgd3 = 0\n",
    "\n",
    "for idx, item in enumerate(sample_dataset):\n",
    "    label = item['label']\n",
    "    if label==0: num_nor0 += 1\n",
    "    elif label==1: num_adc1 += 1\n",
    "    elif label==2: num_hgd2 += 1\n",
    "    elif label==3: num_lgd3 += 1\n",
    "\n",
    "print(\"ADC: \", num_adc1, \"\\nHGD: \", num_hgd2, \"\\nLGD: \", num_lgd3, \"\\nNOR: \", num_nor0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "to_image = transforms.ToPILImage()\n",
    "cnt = 0\n",
    "plt.figure(figsize=(15,8))\n",
    "for item in sample_loader:\n",
    "    if(cnt==10):\n",
    "        break\n",
    "    images = item['image']\n",
    "    labels = item['label']\n",
    "    class_name = ''\n",
    "\n",
    "    if labels==0:\n",
    "        class_name = 'NOR'\n",
    "    elif labels==1:\n",
    "        class_name = 'ADC'\n",
    "    elif labels==2:\n",
    "        class_name = 'HGD'\n",
    "    else:\n",
    "        class_name = 'LGD'\n",
    "\n",
    "    images = to_image(images[0])\n",
    "\n",
    "    \n",
    "    plt.subplot(2,5,cnt+1)\n",
    "    plt.title(class_name)\n",
    "    plt.imshow(images)\n",
    "    cnt+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom CNN network 구현1 - 얼굴 이진 분류 모델에 사용했던 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN_net1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN_net1, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.layer1 = self.conv_module(3,16)\n",
    "        self.layer2 = self.conv_module(16,32)\n",
    "        self.layer3 = self.conv_module(32,64)\n",
    "        self.layer4 = self.conv_module(64,128)\n",
    "        self.layer5 = self.conv_module(128,256)\n",
    "        self.gap = self.global_avg_pooling(256,num_classes)\n",
    "        # self.softmax = nn.Softmax()\n",
    "\n",
    "    def conv_module(self, in_num, out_num):\n",
    "        output = nn.Sequential(nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.BatchNorm2d(out_num),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def global_avg_pooling(self, in_num, out_num):\n",
    "        output = nn.Sequential(nn.Conv2d(in_num, out_num, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.BatchNorm2d(out_num),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.AdaptiveAvgPool2d((1,1)))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(-1,self.num_classes)\n",
    "        # out = self.softmax(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, device):\n",
    "    model.train() # set the model in training mode\n",
    "    sum_loss = 0\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i_batch, item in enumerate(dataloader):\n",
    "\n",
    "        images = item['image'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = crit(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item() * len(images)\n",
    "    \n",
    "    return sum_loss / len(dataloader.dataset)\n",
    "\n",
    "def validate_epoch(dataloader, model, device):\n",
    "    model.eval()\n",
    "    sum_loss = 0\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in dataloader:\n",
    "            images = item['image'].to(device)\n",
    "            labels = item['label'].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = crit(outputs, labels)\n",
    "\n",
    "            sum_loss += loss.item() * len(images)\n",
    "\n",
    "    return sum_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련을 위한 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "from configparser import Interpolation\n",
    "\n",
    "\n",
    "dataset_transforms = transforms.Compose([transforms.Resize((256,256), interpolation=transforms.InterpolationMode.BILINEAR), transforms.ToTensor()])\n",
    "total_dataset = CustomDataset(\"./cropped\", transforms=dataset_transforms)\n",
    "\n",
    "# train, validation, test set 분할\n",
    "dataset_size = total_dataset.num_files\n",
    "train_size = int(dataset_size*0.8)\n",
    "validation_size = int(dataset_size*0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(total_dataset, [train_size, validation_size, test_size])\n",
    "num_classes = total_dataset.num_classes\n",
    "\n",
    "print(\"training data size: {}\".format(train_size))\n",
    "print(\"validation data size: {}\".format(validation_size))\n",
    "print(\"test data size: {}\".format(test_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 분할 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "hyper_epoch = 80\n",
    "hyper_lr = 0.0001\n",
    "hyper_batch = 32\n",
    "\n",
    "# 모델 선언\n",
    "train_loader = DataLoader(train_dataset, batch_size=hyper_batch, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=hyper_batch, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=hyper_batch, shuffle=True)\n",
    "\n",
    "model = CustomCNN_net1(num_classes)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=hyper_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "\n",
    "torchsummary.summary(model,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 모델 저장\n",
    "# PATH = '../../home/bokyoungk/classification_models/net1/'\n",
    "\n",
    "# model = torch.load(PATH+'min_model_21th.pt')\n",
    "# model.load_state_dict(torch.load(PATH+'min_model_state_dict_21th.pt'))\n",
    "# checkpoint = torch.load(PATH+'min_all_21th.tar')\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "# Training\n",
    "# minimal_loss = 1\n",
    "\n",
    "train_loss_list = []\n",
    "validation_loss_list = []\n",
    "\n",
    "for e in range(0,hyper_epoch):\n",
    "    print(\"---------------------epoch no: {}------------------------\".format(e+1))\n",
    "    train_loss = train_epoch(train_loader, model, optimizer, device)\n",
    "    validation_loss = validate_epoch(validation_loader, model, device)\n",
    "    print(\"training loss={}\".format(train_loss))\n",
    "    print(\"validation loss={}\".format(validation_loss))\n",
    "    train_loss_list.append(train_loss)\n",
    "    validation_loss_list.append(validation_loss)\n",
    "    \n",
    "    # 최소 loss epoch 모델 저장\n",
    "    # if minimal_loss > validation_loss:\n",
    "    #     minimal_loss = validation_loss\n",
    "    #     torch.save(model, PATH + 'min_model_{}th.pt'.format(e+1)) # 전체 모델 저장\n",
    "    #     torch.save(model.state_dict(), PATH + 'min_model_state_dict_{}th.pt'.format(e+1))\n",
    "    #     torch.save({\n",
    "    #         'model':model.state_dict(),\n",
    "    #         'optimizer':optimizer.state_dict()\n",
    "    #     }, PATH+'min_all_{}th.tar'.format(e+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 그래프\n",
    "x = np.arange(1,hyper_epoch+1,step=1)\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(x,train_loss_list,label='train loss')\n",
    "plt.plot(x,validation_loss_list, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../home/bokyoungk/classification_models/net1/'\n",
    "model_n = 'min_model_57th.pt'\n",
    "model_st = 'min_model_state_dict_57th.pt'\n",
    "model_all = 'min_all_57th.tar'\n",
    "\n",
    "model = torch.load(PATH + model_n)\n",
    "model.load_state_dict(torch.load(PATH+model_st))\n",
    "\n",
    "checkpoint = torch.load(PATH+model_all)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "\n",
    "# Inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for item in test_loader:\n",
    "        images = item['image'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "        \n",
    "\n",
    "print('Test Accuracy of the model on the {} test images: {}%'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
